{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"sample \u00b6 This is sample package for demo Free software: MIT Documentation: https://sample.readthedocs.io Features \u00b6 TODO Credits \u00b6 This package was created with Cookiecutter and the zillionare/cookiecutter-pypackage project template.","title":"home"},{"location":"#sample","text":"This is sample package for demo Free software: MIT Documentation: https://sample.readthedocs.io","title":"sample"},{"location":"#features","text":"TODO","title":"Features"},{"location":"#credits","text":"This package was created with Cookiecutter and the zillionare/cookiecutter-pypackage project template.","title":"Credits"},{"location":"api/","text":"Top-level package for sample. data_processing \u00b6 Data_hlpr \u00b6 Data Helper is a tool with various static methods help you process and understand your data. dataframestats ( df ) staticmethod \u00b6 Calculates summary stats on a dataframe. Parameters \u00b6 pd.core.frame.DataFrame dataframe Returns \u00b6 d.core.frame.DataFrame A dataframe containg summary stats Source code in sample\\data_processing.py @staticmethod def dataframestats ( df : pd . core . frame . DataFrame ) -> pd . core . frame . DataFrame : \"\"\" Calculates summary stats on a dataframe. Parameters ---------- df: pd.core.frame.DataFrame dataframe Returns ------- types: d.core.frame.DataFrame A dataframe containg summary stats \"\"\" types = pd . DataFrame ( df . dtypes ) types = types . reset_index () types . columns = [ 'VarName' , 'VarType' ] types = types . reindex ( columns = [ * types . columns . tolist (), 'CompleteRecords' , 'MissingRecords' , 'Average' , 'Median' , 'StandardDeviation' , 'Min' , 'Max' , 'UniqueObs' , 'Skewness' ], fill_value = '' ) for i in range ( 0 , len ( types )): types . loc [ i , 'MissingRecords' ] = sum ( pd . isnull ( df [ types [ 'VarName' ][ i ]]) . values . ravel ()) types . loc [ i , 'CompleteRecords' ] = sum ( df [ types [ 'VarName' ][ i ]] . notnull () . values . ravel ()) if str ( df [ types [ 'VarName' ][ i ]] . dtype ) != 'object' : types . loc [ i , 'Average' ] = df [ types [ 'VarName' ][ i ]] . mean () types . loc [ i , 'Median' ] = df [ types [ 'VarName' ][ i ]] . median () types . loc [ i , 'Min' ] = min ( df [ types [ 'VarName' ][ i ]]) types . loc [ i , 'Max' ] = max ( df [ types [ 'VarName' ][ i ]]) types . loc [ i , 'StandardDeviation' ] = df [ types [ 'VarName' ][ i ]] . std () types . loc [ i , 'Skewness' ] = scipy . stats . skew ( df [ types [ 'VarName' ][ i ]], axis = 0 , bias = True ) types . loc [ i , 'UniqueObs' ] = len ( pd . Series ( df [ types [ 'VarName' ][ i ]] . ravel ()) . unique ()) types = types . fillna ( '' ) return types dummycode ( df , dummycode ) staticmethod \u00b6 Converts categorical variables of pandas dataframe into their own binary columns. Parameters \u00b6 pd.core.frame.DataFrame dataframe str The categorical column that will be transposed into a wide binary format. Returns \u00b6 list A list of lists. Source code in sample\\data_processing.py @staticmethod def dummycode ( df : pd . core . frame . DataFrame , dummycode : str ) -> pd . core . frame . DataFrame : \"\"\" Converts categorical variables of pandas dataframe into their own binary columns. Parameters ---------- df: pd.core.frame.DataFrame dataframe dummycode: str The categorical column that will be transposed into a wide binary format. Returns ------- dummies: list A list of lists. \"\"\" dummies = pd . get_dummies ( df [ dummycode ]) dummies = pd . concat ([ df , dummies ], axis = 1 ) dummies = dummies . drop ([ dummycode ], axis = 1 ) return ( dummies ) group_df ( df , cols ) staticmethod \u00b6 Counts values within a column. Parameters \u00b6 pd.core.frame.DataFrame dataframe list The columns you want to aggregate by Returns \u00b6 pd.core.frame.DataFrame A dataframe with the counts by the input columns. Source code in sample\\data_processing.py @staticmethod def group_df ( df : pd . core . frame . DataFrame , cols : list ) -> pd . core . frame . DataFrame : \"\"\" Counts values within a column. Parameters ---------- df: pd.core.frame.DataFrame dataframe cols: list The columns you want to aggregate by Returns ------- output: pd.core.frame.DataFrame A dataframe with the counts by the input columns. \"\"\" end_pos = len ( cols ) output = df . groupby ( cols ) . count () . reset_index () . iloc [:, 0 : end_pos + 1 ] output . columns . values [ end_pos ] = \"Count\" return output pd_expand_dict ( df , dict_col ) staticmethod \u00b6 Expands a dictionary column into 1 to many dataframe columns. Typically, used when applying classifiers onto datasets {\"Class\": \"Apple\", \"Prob\":.44} Parameters \u00b6 pd.core.frame.DataFrame Dataframe str The name of the column containing a dictionary Returns \u00b6 pd.core.frame.DataFrame A dataframe containing keys as the column names and their corresponding values as row observations. Source code in sample\\data_processing.py @staticmethod def pd_expand_dict ( df : pd . core . frame . DataFrame , dict_col : str ) -> pd . core . frame . DataFrame : \"\"\" Expands a dictionary column into 1 to many dataframe columns. Typically, used when applying classifiers onto datasets {\"Class\": \"Apple\", \"Prob\":.44} Parameters ---------- df: pd.core.frame.DataFrame Dataframe dict_col: str The name of the column containing a dictionary Returns ------- result: pd.core.frame.DataFrame A dataframe containing keys as the column names and their corresponding values as row observations. \"\"\" df [ dict_col ] = df [ dict_col ] . astype ( str ) df [ dict_col ] = df [ dict_col ] . apply ( lambda x : dict ( eval ( x ))) df2 = df [ dict_col ] . apply ( pd . Series ) result = pd . concat ([ df , df2 ], axis = 1 ) . drop ( dict_col , axis = 1 ) return ( result ) math \u00b6 lrg_or_not ( param1 , param2 ) \u00b6 Example function with PEP 484 type annotations. Parameters: Name Type Description Default param1 int The first parameter. required param2 Union[int, float] The second parameter. required Returns: Type Description bool The return value. True for success, False otherwise. Source code in sample\\math.py def lrg_or_not ( param1 : int , param2 : Union [ int , float ]) -> bool : \"\"\"Example function with PEP 484 type annotations. Args: param1: The first parameter. param2: The second parameter. Returns: The return value. True for success, False otherwise. \"\"\" return param1 > param2 nlp \u00b6 chunks ( lst , n ) \u00b6 Converts a list into chunks of smaller lists. Parameters \u00b6 list Input list int The number of bins Returns \u00b6 list A list of lists. Source code in sample\\nlp.py def chunks ( lst : list , n : int ) -> list : \"\"\" Converts a list into chunks of smaller lists. Parameters ---------- lst: list Input list n: int The number of bins Returns ------- chunks: list A list of lists. \"\"\" chunks = [ lst [ x : x + n ] for x in range ( 0 , len ( lst ), n )] return chunks","title":"modules"},{"location":"api/#sample.data_processing","text":"","title":"data_processing"},{"location":"api/#sample.data_processing.Data_hlpr","text":"Data Helper is a tool with various static methods help you process and understand your data.","title":"Data_hlpr"},{"location":"api/#sample.data_processing.Data_hlpr.dataframestats","text":"Calculates summary stats on a dataframe.","title":"dataframestats()"},{"location":"api/#sample.data_processing.Data_hlpr.dataframestats--parameters","text":"pd.core.frame.DataFrame dataframe","title":"Parameters"},{"location":"api/#sample.data_processing.Data_hlpr.dataframestats--returns","text":"d.core.frame.DataFrame A dataframe containg summary stats Source code in sample\\data_processing.py @staticmethod def dataframestats ( df : pd . core . frame . DataFrame ) -> pd . core . frame . DataFrame : \"\"\" Calculates summary stats on a dataframe. Parameters ---------- df: pd.core.frame.DataFrame dataframe Returns ------- types: d.core.frame.DataFrame A dataframe containg summary stats \"\"\" types = pd . DataFrame ( df . dtypes ) types = types . reset_index () types . columns = [ 'VarName' , 'VarType' ] types = types . reindex ( columns = [ * types . columns . tolist (), 'CompleteRecords' , 'MissingRecords' , 'Average' , 'Median' , 'StandardDeviation' , 'Min' , 'Max' , 'UniqueObs' , 'Skewness' ], fill_value = '' ) for i in range ( 0 , len ( types )): types . loc [ i , 'MissingRecords' ] = sum ( pd . isnull ( df [ types [ 'VarName' ][ i ]]) . values . ravel ()) types . loc [ i , 'CompleteRecords' ] = sum ( df [ types [ 'VarName' ][ i ]] . notnull () . values . ravel ()) if str ( df [ types [ 'VarName' ][ i ]] . dtype ) != 'object' : types . loc [ i , 'Average' ] = df [ types [ 'VarName' ][ i ]] . mean () types . loc [ i , 'Median' ] = df [ types [ 'VarName' ][ i ]] . median () types . loc [ i , 'Min' ] = min ( df [ types [ 'VarName' ][ i ]]) types . loc [ i , 'Max' ] = max ( df [ types [ 'VarName' ][ i ]]) types . loc [ i , 'StandardDeviation' ] = df [ types [ 'VarName' ][ i ]] . std () types . loc [ i , 'Skewness' ] = scipy . stats . skew ( df [ types [ 'VarName' ][ i ]], axis = 0 , bias = True ) types . loc [ i , 'UniqueObs' ] = len ( pd . Series ( df [ types [ 'VarName' ][ i ]] . ravel ()) . unique ()) types = types . fillna ( '' ) return types","title":"Returns"},{"location":"api/#sample.data_processing.Data_hlpr.dummycode","text":"Converts categorical variables of pandas dataframe into their own binary columns.","title":"dummycode()"},{"location":"api/#sample.data_processing.Data_hlpr.dummycode--parameters","text":"pd.core.frame.DataFrame dataframe str The categorical column that will be transposed into a wide binary format.","title":"Parameters"},{"location":"api/#sample.data_processing.Data_hlpr.dummycode--returns","text":"list A list of lists. Source code in sample\\data_processing.py @staticmethod def dummycode ( df : pd . core . frame . DataFrame , dummycode : str ) -> pd . core . frame . DataFrame : \"\"\" Converts categorical variables of pandas dataframe into their own binary columns. Parameters ---------- df: pd.core.frame.DataFrame dataframe dummycode: str The categorical column that will be transposed into a wide binary format. Returns ------- dummies: list A list of lists. \"\"\" dummies = pd . get_dummies ( df [ dummycode ]) dummies = pd . concat ([ df , dummies ], axis = 1 ) dummies = dummies . drop ([ dummycode ], axis = 1 ) return ( dummies )","title":"Returns"},{"location":"api/#sample.data_processing.Data_hlpr.group_df","text":"Counts values within a column.","title":"group_df()"},{"location":"api/#sample.data_processing.Data_hlpr.group_df--parameters","text":"pd.core.frame.DataFrame dataframe list The columns you want to aggregate by","title":"Parameters"},{"location":"api/#sample.data_processing.Data_hlpr.group_df--returns","text":"pd.core.frame.DataFrame A dataframe with the counts by the input columns. Source code in sample\\data_processing.py @staticmethod def group_df ( df : pd . core . frame . DataFrame , cols : list ) -> pd . core . frame . DataFrame : \"\"\" Counts values within a column. Parameters ---------- df: pd.core.frame.DataFrame dataframe cols: list The columns you want to aggregate by Returns ------- output: pd.core.frame.DataFrame A dataframe with the counts by the input columns. \"\"\" end_pos = len ( cols ) output = df . groupby ( cols ) . count () . reset_index () . iloc [:, 0 : end_pos + 1 ] output . columns . values [ end_pos ] = \"Count\" return output","title":"Returns"},{"location":"api/#sample.data_processing.Data_hlpr.pd_expand_dict","text":"Expands a dictionary column into 1 to many dataframe columns. Typically, used when applying classifiers onto datasets {\"Class\": \"Apple\", \"Prob\":.44}","title":"pd_expand_dict()"},{"location":"api/#sample.data_processing.Data_hlpr.pd_expand_dict--parameters","text":"pd.core.frame.DataFrame Dataframe str The name of the column containing a dictionary","title":"Parameters"},{"location":"api/#sample.data_processing.Data_hlpr.pd_expand_dict--returns","text":"pd.core.frame.DataFrame A dataframe containing keys as the column names and their corresponding values as row observations. Source code in sample\\data_processing.py @staticmethod def pd_expand_dict ( df : pd . core . frame . DataFrame , dict_col : str ) -> pd . core . frame . DataFrame : \"\"\" Expands a dictionary column into 1 to many dataframe columns. Typically, used when applying classifiers onto datasets {\"Class\": \"Apple\", \"Prob\":.44} Parameters ---------- df: pd.core.frame.DataFrame Dataframe dict_col: str The name of the column containing a dictionary Returns ------- result: pd.core.frame.DataFrame A dataframe containing keys as the column names and their corresponding values as row observations. \"\"\" df [ dict_col ] = df [ dict_col ] . astype ( str ) df [ dict_col ] = df [ dict_col ] . apply ( lambda x : dict ( eval ( x ))) df2 = df [ dict_col ] . apply ( pd . Series ) result = pd . concat ([ df , df2 ], axis = 1 ) . drop ( dict_col , axis = 1 ) return ( result )","title":"Returns"},{"location":"api/#sample.math","text":"","title":"math"},{"location":"api/#sample.math.lrg_or_not","text":"Example function with PEP 484 type annotations. Parameters: Name Type Description Default param1 int The first parameter. required param2 Union[int, float] The second parameter. required Returns: Type Description bool The return value. True for success, False otherwise. Source code in sample\\math.py def lrg_or_not ( param1 : int , param2 : Union [ int , float ]) -> bool : \"\"\"Example function with PEP 484 type annotations. Args: param1: The first parameter. param2: The second parameter. Returns: The return value. True for success, False otherwise. \"\"\" return param1 > param2","title":"lrg_or_not()"},{"location":"api/#sample.nlp","text":"","title":"nlp"},{"location":"api/#sample.nlp.chunks","text":"Converts a list into chunks of smaller lists.","title":"chunks()"},{"location":"api/#sample.nlp.chunks--parameters","text":"list Input list int The number of bins","title":"Parameters"},{"location":"api/#sample.nlp.chunks--returns","text":"list A list of lists. Source code in sample\\nlp.py def chunks ( lst : list , n : int ) -> list : \"\"\" Converts a list into chunks of smaller lists. Parameters ---------- lst: list Input list n: int The number of bins Returns ------- chunks: list A list of lists. \"\"\" chunks = [ lst [ x : x + n ] for x in range ( 0 , len ( lst ), n )] return chunks","title":"Returns"},{"location":"authors/","text":"Credits \u00b6 Development Lead \u00b6 Christopher Mooney cmooney@carhartt.com Contributors \u00b6 None yet. Why not be the first?","title":"authors"},{"location":"authors/#credits","text":"","title":"Credits"},{"location":"authors/#development-lead","text":"Christopher Mooney cmooney@carhartt.com","title":"Development Lead"},{"location":"authors/#contributors","text":"None yet. Why not be the first?","title":"Contributors"},{"location":"contributing/","text":"Contributing \u00b6 Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways: Types of Contributions \u00b6 Report Bugs \u00b6 Report bugs at https://github.com/cmooney/sample/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug. Fix Bugs \u00b6 Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it. Implement Features \u00b6 Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it. Write Documentation \u00b6 sample could always use more documentation, whether as part of the official sample docs, in docstrings, or even on the web in blog posts, articles, and such. Submit Feedback \u00b6 The best way to send feedback is to file an issue at https://github.com/cmooney/sample/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :) Get Started! \u00b6 Ready to contribute? Here's how to set up sample for local development. Fork the sample repo on GitHub. Clone your fork locally 1 $ git clone git@github.com:your_name_here/sample.git Ensure poetry is installed. Install dependencies and start your virtualenv: 1 $ poetry install -E test -E doc -E dev Create a branch for local development: 1 $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: 1 $ tox Commit your changes and push your branch to GitHub: 1 2 3 $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website. Pull Request Guidelines \u00b6 Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8, 3.9 and for PyPy. Check https://github.com/cmooney/sample/actions and make sure that the tests pass for all supported Python versions. Tips``` \u00b6 1 $ pytest tests.test_sample ```To run a subset of tests. Deploying \u00b6 A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in HISTORY.md). Then run: 1 2 3 $ poetry patch # possible: major / minor / patch $ git push $ git push --tags Travis will then deploy to PyPI if tests pass.","title":"contributing"},{"location":"contributing/#contributing","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways:","title":"Contributing"},{"location":"contributing/#types-of-contributions","text":"","title":"Types of Contributions"},{"location":"contributing/#report-bugs","text":"Report bugs at https://github.com/cmooney/sample/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug.","title":"Report Bugs"},{"location":"contributing/#fix-bugs","text":"Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.","title":"Fix Bugs"},{"location":"contributing/#implement-features","text":"Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.","title":"Implement Features"},{"location":"contributing/#write-documentation","text":"sample could always use more documentation, whether as part of the official sample docs, in docstrings, or even on the web in blog posts, articles, and such.","title":"Write Documentation"},{"location":"contributing/#submit-feedback","text":"The best way to send feedback is to file an issue at https://github.com/cmooney/sample/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :)","title":"Submit Feedback"},{"location":"contributing/#get-started","text":"Ready to contribute? Here's how to set up sample for local development. Fork the sample repo on GitHub. Clone your fork locally 1 $ git clone git@github.com:your_name_here/sample.git Ensure poetry is installed. Install dependencies and start your virtualenv: 1 $ poetry install -E test -E doc -E dev Create a branch for local development: 1 $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: 1 $ tox Commit your changes and push your branch to GitHub: 1 2 3 $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website.","title":"Get Started!"},{"location":"contributing/#pull-request-guidelines","text":"Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8, 3.9 and for PyPy. Check https://github.com/cmooney/sample/actions and make sure that the tests pass for all supported Python versions.","title":"Pull Request Guidelines"},{"location":"contributing/#tips","text":"1 $ pytest tests.test_sample ```To run a subset of tests.","title":"Tips```"},{"location":"contributing/#deploying","text":"A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in HISTORY.md). Then run: 1 2 3 $ poetry patch # possible: major / minor / patch $ git push $ git push --tags Travis will then deploy to PyPI if tests pass.","title":"Deploying"},{"location":"history/","text":"History \u00b6 0.1.0 (2021-11-12) \u00b6 First release on PyPI.","title":"history"},{"location":"history/#history","text":"","title":"History"},{"location":"history/#010-2021-11-12","text":"First release on PyPI.","title":"0.1.0 (2021-11-12)"},{"location":"installation/","text":"Installation \u00b6 Stable release \u00b6 To install sample, run this command in your terminal: 1 $ pip install sample This is the preferred method to install sample, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process. From source \u00b6 The source for sample can be downloaded from the Github repo . You can either clone the public repository: 1 $ git clone git://github.com/cmooney/sample Or download the tarball : 1 $ curl -OJL https://github.com/cmooney/sample/tarball/master Once you have a copy of the source, you can install it with: 1 $ pip install .","title":"installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#stable-release","text":"To install sample, run this command in your terminal: 1 $ pip install sample This is the preferred method to install sample, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process.","title":"Stable release"},{"location":"installation/#from-source","text":"The source for sample can be downloaded from the Github repo . You can either clone the public repository: 1 $ git clone git://github.com/cmooney/sample Or download the tarball : 1 $ curl -OJL https://github.com/cmooney/sample/tarball/master Once you have a copy of the source, you can install it with: 1 $ pip install .","title":"From source"},{"location":"usage/","text":"Usage \u00b6 To use sample in a project 1 import sample","title":"usage"},{"location":"usage/#usage","text":"To use sample in a project 1 import sample","title":"Usage"}]}